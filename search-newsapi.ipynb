{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "os.makedirs(\"output\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"queries/search_queries_ru.json\", \"r\") as f:\n",
    "    queries_ru = json.load(f)\n",
    "with open(\"queries/search_queries.json\", \"r\") as f:\n",
    "    queries_en = json.load(f)\n",
    "\n",
    "queries_list_ru = [{\"query\": q, \"category\": cat} for cat in queries_ru for q in queries_ru[cat]]\n",
    "queries_list_en = [{\"query\": q, \"category\": cat} for cat in queries_en for q in queries_en[cat]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get date of 7 days before today\n",
    "from datetime import datetime, timedelta\n",
    "date = datetime.today() - timedelta(days=7)\n",
    "date = date.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newsapi import NewsApiClient\n",
    "\n",
    "newsapi = NewsApiClient(api_key='80f585e493484c3abf0a8b946ddccf5d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_items = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = \"ru\"\n",
    "\n",
    "for i, query_d in enumerate(queries_list_ru):\n",
    "    query = query_d[\"query\"]\n",
    "    category = query_d[\"category\"]\n",
    "\n",
    "    res = newsapi.get_everything(\n",
    "        q=query,\n",
    "        from_param=date,\n",
    "        language=lang,\n",
    "        sort_by='relevancy',\n",
    "        # page_size=100,\n",
    "        page=1\n",
    "    )\n",
    "    print(f\"Searching for {query}, {i}/{len(queries_list_ru)}, found {res['totalResults']} articles\")\n",
    "    articles = res[\"articles\"]\n",
    "\n",
    "    for item in articles:\n",
    "        item.pop(\"content\")\n",
    "        url_items.append({\n",
    "            **item,\n",
    "            \"query\": query,\n",
    "            \"category\": category,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for Latest products in the steel industry, 0/69, found 69 articles\n",
      "Searching for New initiatives by leading steel companies, 1/69, found 12 articles\n",
      "Searching for Competitor analysis steel industry, 2/69, found 1 articles\n",
      "Searching for Innovations in steel production, 3/69, found 11 articles\n",
      "Searching for New steel products market trends, 4/69, found 34 articles\n",
      "Searching for Innovative data storage solutions for the steel industry, 5/69, found 3 articles\n",
      "Searching for Data management trends in metallurgy, 6/69, found 4 articles\n",
      "Searching for Best practices for data storage in manufacturing, 7/69, found 13 articles\n",
      "Searching for Cloud solutions for steel manufacturing, 8/69, found 5 articles\n",
      "Searching for Big data in steel industry, 9/69, found 15 articles\n",
      "Searching for AI applications in steel industry, 10/69, found 8 articles\n",
      "Searching for Artificial intelligence in metallurgy, 11/69, found 1 articles\n",
      "Searching for Top startups in steel and metallurgy, 12/69, found 0 articles\n",
      "Searching for Innovative AI solutions for manufacturing, 13/69, found 74 articles\n",
      "Searching for Machine learning in steel production, 14/69, found 10 articles\n",
      "Searching for New regulations in the steel industry, 15/69, found 25 articles\n",
      "Searching for Legislative changes in metallurgy, 16/69, found 4 articles\n",
      "Searching for Environmental regulations for steel manufacturers, 17/69, found 3 articles\n",
      "Searching for Compliance requirements for steel industry, 18/69, found 6 articles\n"
     ]
    },
    {
     "ename": "NewsAPIException",
     "evalue": "{'status': 'error', 'code': 'rateLimited', 'message': 'You have made too many requests recently. Developer accounts are limited to 100 requests over a 24 hour period (50 requests available every 12 hours). Please upgrade to a paid plan if you need more requests.'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNewsAPIException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m query \u001b[38;5;241m=\u001b[39m query_d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m category \u001b[38;5;241m=\u001b[39m query_d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mnewsapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_everything\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_param\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlang\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort_by\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelevancy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# page_size=100,\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearching for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(queries_list_en)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotalResults\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m articles\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m articles \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marticles\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/newsapi/newsapi_client.py:334\u001b[0m, in \u001b[0;36mNewsApiClient.get_everything\u001b[0;34m(self, q, qintitle, sources, domains, exclude_domains, from_param, to, language, sort_by, page, page_size)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# Check Status of Request\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m requests\u001b[38;5;241m.\u001b[39mcodes\u001b[38;5;241m.\u001b[39mok:\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewsAPIException(r\u001b[38;5;241m.\u001b[39mjson())\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\u001b[38;5;241m.\u001b[39mjson()\n",
      "\u001b[0;31mNewsAPIException\u001b[0m: {'status': 'error', 'code': 'rateLimited', 'message': 'You have made too many requests recently. Developer accounts are limited to 100 requests over a 24 hour period (50 requests available every 12 hours). Please upgrade to a paid plan if you need more requests.'}"
     ]
    }
   ],
   "source": [
    "lang = \"en\"\n",
    "\n",
    "for i, query_d in enumerate(queries_list_en):\n",
    "    query = query_d[\"query\"]\n",
    "    category = query_d[\"category\"]\n",
    "\n",
    "    res = newsapi.get_everything(\n",
    "        q=query,\n",
    "        from_param=date,\n",
    "        language=lang,\n",
    "        sort_by='relevancy',\n",
    "        # page_size=100,\n",
    "        page=1\n",
    "    )\n",
    "    print(f\"Searching for {query}, {i}/{len(queries_list_en)}, found {res['totalResults']} articles\")\n",
    "    articles = res[\"articles\"]\n",
    "\n",
    "    for item in articles:\n",
    "        item.pop(\"content\")\n",
    "        url_items.append({\n",
    "            **item,\n",
    "            \"query\": query,\n",
    "            \"category\": category,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save URLs\n",
    "with open(\"output/urls_newsapi.json\", \"w\") as f:\n",
    "    json.dump(url_items, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter and Count Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate_urls(url_items):\n",
    "    urls_dedupl = {}\n",
    "\n",
    "    urls = [item['url'] for item in url_items]\n",
    "    counter = Counter(urls)\n",
    "    for item in url_items:\n",
    "        url = item['url']\n",
    "        if urls_dedupl.get(url):\n",
    "            continue\n",
    "        urls_dedupl[url] = item\n",
    "        urls_dedupl[url]['count'] = counter[url]\n",
    "\n",
    "    assert len(urls_dedupl) == len(counter)\n",
    "    return list(urls_dedupl.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_items = deduplicate_urls(url_items)\n",
    "\n",
    "with open(\"output/urls_newsapi_filtered.json\", \"w\") as f:\n",
    "    json.dump(url_items, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(url_items)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
